{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import json\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import argparse\n",
    "import copy\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from scipy.misc import imsave, imresize\n",
    "from scipy.ndimage import imread\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'                              # Where to store temporary files\n",
    "PUBLIC_PATH = 'public'                          # Where to show graphs and diagnostics\n",
    "EGOCENTRIC_IMAGE_FOLDER = 'egocentric_images'   # Where egocentric images are stored\n",
    "TMP_PATH = 'tmp'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_hash = 4023239360457093510\n",
    "experiment_hash = 8841606304273805265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL\n",
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print 'TRAINING MODEL'\n",
    "print 'Loading data'\n",
    "\n",
    "X = np.load('X_%d.npy' % feature_hash)\n",
    "y = np.load('y_%d.npy' % feature_hash)\n",
    "t = np.load('t_%d.npy' % feature_hash)\n",
    "print(\"Load Done...\")\n",
    "assert X.shape[0] == y.shape[0] == t.shape[0]\n",
    "split_mask = np.load('split_mask_%d.npy' % experiment_hash)\n",
    "\n",
    "\n",
    "X_train = X[split_mask == 'train']\n",
    "X_val = X[split_mask == 'val']\n",
    "X_test = X[split_mask == 'test']\n",
    "\n",
    "y_train = y[split_mask == 'train']\n",
    "y_val = y[split_mask == 'val']\n",
    "y_test = y[split_mask == 'test']\n",
    "\n",
    "t_train = t[split_mask == 'train']\n",
    "t_val = t[split_mask == 'val']\n",
    "t_test = t[split_mask == 'test']\n",
    "\n",
    "X_train = X_train.clip(0, 1)\n",
    "X_val = X_val.clip(0, 1)\n",
    "X_test = X_test.clip(0, 1)\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0] == t_train.shape[0]\n",
    "assert X_val.shape[0] == y_val.shape[0] == t_val.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "((X_train, t_train), y_train) = util.balance((X_train, t_train), y_train)\n",
    "((X_val, t_val), y_val) = util.balance((X_val, t_val), y_val)\n",
    "((X_test, t_test), y_test) = util.balance((X_test, t_test), y_test)\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0] == t_train.shape[0]\n",
    "assert X_val.shape[0] == y_val.shape[0] == t_val.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reshape X Train...\")\n",
    "tempLength = args.LOOKAHEAD + args.LOOKBEHIND + 1\n",
    "X_train = X_train.reshape((X_train.shape[0], tempLength, X_train.shape[1]//tempLength))\n",
    "X_val = X_val.reshape((X_val.shape[0], tempLength, X_val.shape[1]//tempLength))\n",
    "X_test = X_test.reshape((X_test.shape[0], tempLength, X_test.shape[1]//tempLength))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(3, return_sequences=False), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, W_regularizer=l2(args.C), activation='sigmoid'))\n",
    "model.summary()\n",
    "np.random.seed(args.RANDOM_SEED)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=args.LR), metrics=['accuracy'])\n",
    "print 'Training model'\n",
    "model.fit(X_train, y_train, nb_epoch=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[EarlyStopping(patience=3)])\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Saving predictions'\n",
    "X = np.load('X_%d.npy' % feature_hash)\n",
    "\n",
    "if args.MODEL == 'keras':\n",
    "    model.save('model_%d.h5' % experiment_hash)\n",
    "    X = X.reshape((X.shape[0], tempLength, X.shape[1]//tempLength))\n",
    "    y_prob = model.predict_proba(X)\n",
    "    y_hat = model.predict_classes(X)\n",
    "elif args.MODEL == 'svm':\n",
    "    y_prob = 1.0 / (1.0 + np.exp(-model.decision_function(X)))\n",
    "    y_hat = model.predict(X)\n",
    "elif args.MODEL == 'logistic_regression':\n",
    "    y_hat = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1].flatten()\n",
    "else:\n",
    "    assert False, 'Unknown model: %d' % args.MODEL\n",
    "\n",
    "\n",
    "np.save('y_prob_%d.npy' % experiment_hash, y_prob)\n",
    "np.save('y_hat_%d.npy' % experiment_hash, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
