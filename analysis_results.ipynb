{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"analysis_results.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"JfzFyFRXqaPk","colab_type":"text"},"cell_type":"markdown","source":["Analysis Results"]},{"metadata":{"id":"LA4KWoYGztBq","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"UpBPrBEiqlac","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":107},"outputId":"686815eb-d660-4d79-e089-a970275fcaf7","executionInfo":{"status":"ok","timestamp":1533090835321,"user_tz":-420,"elapsed":11305,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# Connect Google drive\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"NnNeLMeADE-O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# change directory to mistaken\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0NgvYDlMJSVF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"eed71638-026d-4577-9fea-b686c9139421","executionInfo":{"status":"ok","timestamp":1533137991968,"user_tz":-420,"elapsed":2632,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["!ls"],"execution_count":1,"outputs":[{"output_type":"stream","text":["datalab  drive\r\n"],"name":"stdout"}]},{"metadata":{"id":"frlgw57kqpN5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3366},"outputId":"7558038f-8cc9-4c49-fdfb-9df7a29d8e5d","executionInfo":{"status":"ok","timestamp":1533138005446,"user_tz":-420,"elapsed":8227,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["import os\n","os.chdir('drive')\n","os.chdir('mistaken')\n","!ls -l "],"execution_count":2,"outputs":[{"output_type":"stream","text":["total 136475072\r\n","drwxr-xr-x 2 root root        4096 Mar  5 06:24 afs\r\n","drwxr-xr-x 2 root root        4096 Apr  4 04:26 afs1\r\n","-rw-r--r-- 1 root root   353725242 Apr  4 04:22 afs1.zip\r\n","-rw-r--r-- 1 root root       79141 Aug  1 15:39 analysis_results.ipynb\r\n","-rw-r--r-- 1 root root        1569 Jun 20 14:31 a.npy\r\n","drwxr-xr-x 2 root root        4096 Jun 14 05:47 batch_files\r\n","-rw-r--r-- 1 root root       34151 Mar  5 09:27 big_living_background.png\r\n","-rw-r--r-- 1 root root       47809 Mar  5 09:27 big_park_background.png\r\n","-rw-r--r-- 1 root root     7286409 Mar  5 06:26 caffe\r\n","-rw-r--r-- 1 root root        9321 May 12 05:55 concatenate_feature.py\r\n","drwxr-xr-x 2 root root        4096 Apr 11 11:00 concatenate_feature_resnet50\r\n","-rw-r--r-- 1 root root      581355 May  7 04:00 concat_indices_200000000000.json\r\n","-rw-r--r-- 1 root root      586640 Apr 16 12:36 concat_indices_2223320934302811922.json\r\n","-rw-r--r-- 1 root root      586640 Jun 12 08:10 concat_indices_2408.json\r\n","-rw-r--r-- 1 root root      586640 Apr  9 06:12 concat_indices_2912102996873951606.json\r\n","-rw-r--r-- 1 root root      586640 May 12 10:41 concat_indices_300000000000.json\r\n","-rw-r--r-- 1 root root      586640 Mar 13 16:06 concat_indices_4023239360457093510.json\r\n","-rw-r--r-- 1 root root      586640 Apr 16 04:46 concat_indices_438455043325458450.json\r\n","-rw-r--r-- 1 root root      586640 May 30 23:24 concat_indices_5000.json\r\n","-rw-r--r-- 1 root root      586640 Jun  4 13:57 concat_indices_60000.json\r\n","drwxr-xr-x 2 root root        4096 Jun 28 06:52 convnets-keras\r\n","drwxr-xr-x 2 root root        4096 Mar  5 06:24 convSVM\r\n","-rw-r--r-- 1 root root       42184 Apr  6 14:39 Copy of Untitled0.ipynb\r\n","-rw-r--r-- 1 root root      408958 Jun 28 07:48 Copy of Untitled0.ipynb.invalid\r\n","drwxr-xr-x 2 root root        4096 Mar  5 06:25 data\r\n","-rw-r--r-- 1 root root      763693 Aug  1 13:00 Demo.ipynb\r\n","-rw-r--r-- 1 root root        2726 Jul 28 05:53 demo_scene.txt\r\n","drwxr-xr-x 2 root root        4096 Mar  5 09:04 drive\r\n","drwxr-xr-x 2 root root        4096 Mar  5 09:41 egocentric_images\r\n","drwxr-xr-x 2 root root        4096 Apr  3 03:34 egocentric_images_2\r\n","-rw-r--r-- 1 root root        2867 Apr 11 06:20 extract_feature.py\r\n","-rw-r--r-- 1 root root     1642329 Jun 12 07:55 get-pip.py\r\n","-rw-r--r-- 1 root root      490155 May  7 04:02 image_filename_vec_200000000000.json\r\n","-rw-r--r-- 1 root root      490155 Apr 16 12:37 image_filename_vec_2223320934302811922.json\r\n","-rw-r--r-- 1 root root      490155 Jun 12 08:11 image_filename_vec_2408.json\r\n","-rw-r--r-- 1 root root      490155 Apr  9 06:12 image_filename_vec_2912102996873951606.json\r\n","-rw-r--r-- 1 root root      490155 May 12 10:43 image_filename_vec_300000000000.json\r\n","-rw-r--r-- 1 root root      490155 Mar 13 16:08 image_filename_vec_4023239360457093510.json\r\n","-rw-r--r-- 1 root root      490155 Apr 16 04:46 image_filename_vec_438455043325458450.json\r\n","-rw-r--r-- 1 root root      490155 Jun  4 13:58 image_filename_vec_60000.json\r\n","-rw-r--r-- 1 root root      490155 Apr  7 05:41 image_filename_vec_resnet50.json\r\n","drwxr-xr-x 2 root root        4096 Jun 11 05:23 images\r\n","-rw-r--r-- 1 root root       31761 May 23 23:50 Ket_Qua (version 1) (44ce96cf).xlsb.xlsx\r\n","-rw-r--r-- 1 root root      140115 Jun 29 06:12 Ket_Qua-version-1-version-1.xlsb_thuy.xlsx\r\n","-rw-r--r-- 1 root root       82970 Jun 21 05:05 Ket_Qua (version 1) (version 1).xlsb.xlsx\r\n","-rw-r--r-- 1 root root       31761 May 23 23:50 Ket_Qua (version 1).xlsb.xlsx\r\n","-rw-r--r-- 1 root root       25697 Mar  5 09:27 living_bg1.png\r\n","-rw-r--r-- 1 root root       45559 Apr 16 06:32 mistaken_download.py\r\n","-rw-r--r-- 1 root root       55771 May 14 04:00 mistaken_edit.py\r\n","-rw-r--r-- 1 root root       63247 Jun 30 09:00 mistaken.py\r\n","-rw-r--r-- 1 root root     6783672 May 13 21:23 model_2305240994148776829.h5\r\n","-rw-r--r-- 1 root root      221880 May 10 03:02 model_3277221850808793978.h5\r\n","-rw-r--r-- 1 root root      190832 May 10 02:39 model_6128076522482830630.h5\r\n","-rw-r--r-- 1 root root      425496 Apr 11 20:05 model_776890777140245298.h5\r\n","-rw-r--r-- 1 root root     5932400 May 14 04:37 model_8035819618733567531.h5\r\n","-rw-r--r-- 1 root root     6783672 May 14 03:55 model_8143401490449226444.h5\r\n","-rw-r--r-- 1 root root     5438012 Jun 30 09:27 model_8647626824687750802.h5\r\n","-rw-r--r-- 1 root root     5438012 Jun 30 09:27 model.h5\r\n","-rw-r--r-- 1 root root   283468976 Jun 28 18:35 model_Nthuy.h5\r\n","-rw-r--r-- 1 root root   283471728 Jun 28 21:39 model_NthuyTHACH.h5\r\n","-rw-r--r-- 1 root root       40190 May  7 02:12 multithread_concatenate_features.py\r\n","-rw-r--r-- 1 root root       89202 Jun 29 05:11 NgocThuyXinhdep.ipynb\r\n","-r--r--r-- 1 root root       24807 Apr 10 03:25 old_mistaken.py.odt\r\n","-rw-r--r-- 1 root root       42114 Mar  5 09:27 park_bg1.png\r\n","-rw-r--r-- 1 root root     1217225 Jun 28 21:54 PhienBan2NTModel.ipynb\r\n","drwxr-xr-x 2 root root        4096 Mar  5 06:24 public\r\n","-rw-r--r-- 1 root root       17542 Mar  7 10:20 render_scenes_json.py\r\n","-rw-r--r-- 1 root root       11988 Mar  7 10:23 render_scenes_json.pyc\r\n","drwxr-xr-x 2 root root        4096 Jun  8 03:18 resnet50_concatenate_features\r\n","drwxr-xr-x 2 root root        4096 Apr  5 13:33 resnet50_features\r\n","drwxr-xr-x 2 root root        4096 Apr 10 10:31 resnet50_features_original_size\r\n","drwxr-xr-x 2 root root        4096 Jun 16 07:27 results\r\n","drwxr-xr-x 2 root root        4096 Jun 28 06:45 results_2\r\n","-rw-r--r-- 1 root root      572776 Jun 20 05:29 run_test.ipynb\r\n","-rw-r--r-- 1 root root        6503 Apr  3 02:56 run_test_lstm.ipynb\r\n","-rw-r--r-- 1 root root      630693 Jul 27 17:12 scene_description.json\r\n","-rw-r--r-- 1 root root      406470 May  7 04:01 scene_id_vec_200000000000.json\r\n","-rw-r--r-- 1 root root      406470 Apr 16 12:36 scene_id_vec_2223320934302811922.json\r\n","-rw-r--r-- 1 root root      406470 Jun 12 08:11 scene_id_vec_2408.json\r\n","-rw-r--r-- 1 root root      406470 Apr  9 06:12 scene_id_vec_2912102996873951606.json\r\n","-rw-r--r-- 1 root root      406470 May 12 10:42 scene_id_vec_300000000000.json\r\n","-rw-r--r-- 1 root root      406470 Mar 13 16:07 scene_id_vec_4023239360457093510.json\r\n","-rw-r--r-- 1 root root      406470 Apr 16 04:46 scene_id_vec_438455043325458450.json\r\n","-rw-r--r-- 1 root root      406470 Jun  4 13:58 scene_id_vec_60000.json\r\n","-rw-r--r-- 1 root root      406470 Apr  7 05:41 scene_id_vec_resnet50.json\r\n","-rw-r--r-- 1 root root      239228 May 14 11:02 split_mask_1182471099183327604.npy\r\n","-rw-r--r-- 1 root root      239228 Apr  9 06:12 split_mask_1182953638226861357.npy\r\n","-rw-r--r-- 1 root root      239228 Jun 15 01:40 split_mask_1516386097573094802.npy\r\n","-rw-r--r-- 1 root root      239228 Apr  9 06:25 split_mask_180116985742033011.npy\r\n","-rw-r--r-- 1 root root      239228 May 14 05:03 split_mask_2008162476980562647.npy\r\n","-rw-r--r-- 1 root root      239228 May 14 05:25 split_mask_2305240994148776829.npy\r\n","-rw-r--r-- 1 root root      239228 Apr 18 09:04 split_mask_2600180050185586121.npy\r\n","-rw-r--r-- 1 root root      239228 Jun 15 01:47 split_mask_2983505177517327716.npy\r\n","-rw-r--r-- 1 root root      239228 May 10 02:42 split_mask_3277221850808793978.npy\r\n","-rw-r--r-- 1 root root      239228 May 14 05:52 split_mask_4754952150018512305.npy\r\n","-rw-r--r-- 1 root root      239228 Jun 15 01:44 split_mask_5305626107254735877.npy\r\n","-rw-r--r-- 1 root root      239228 Jun  5 03:19 split_mask_5568321397427174677.npy\r\n","-rw-r--r-- 1 root root      239228 May 10 02:37 split_mask_6128076522482830630.npy\r\n","-rw-r--r-- 1 root root      239228 Apr  9 06:18 split_mask_776890777140245298.npy\r\n","-rw-r--r-- 1 root root      239228 Apr  9 06:45 split_mask_7889190258438680648.npy\r\n","-rw-r--r-- 1 root root      239228 May 12 01:42 split_mask_7949521252375334267.npy\r\n","-rw-r--r-- 1 root root      239228 May 14 04:03 split_mask_8035819618733567531.npy\r\n","-rw-r--r-- 1 root root      239228 Jun 15 07:21 split_mask_8076488538840229141.npy\r\n","-rw-r--r-- 1 root root      239228 May 13 21:29 split_mask_8143401490449226444.npy\r\n","-rw-r--r-- 1 root root      239228 May 14 16:05 split_mask_8647626824687750802.npy\r\n","-rw-r--r-- 1 root root      239228 Jun 16 05:49 split_mask_8841606304273805265.npy\r\n","-rw-r--r-- 1 root root      239228 May 14 08:26 split_mask_8949258729311709173.npy\r\n","-rw-r--r-- 1 root root      239228 May  7 04:04 split_mask_909239567070247466.npy\r\n","-rw-r--r-- 1 root root         329 Mar 12 13:24 split_test_egocentric_features.py\r\n","-rw-r--r-- 1 root root       95768 May  7 03:59 t_200000000000.npy\r\n","-rw-r--r-- 1 root root       95768 Apr 16 12:35 t_2223320934302811922.npy\r\n","-rw-r--r-- 1 root root       95768 Jun 12 08:10 t_2408.npy\r\n","-rw-r--r-- 1 root root       95768 Apr  9 06:12 t_2912102996873951606.npy\r\n","-rw-r--r-- 1 root root       95768 May 12 10:39 t_300000000000.npy\r\n","-rw-r--r-- 1 root root       95768 Mar 13 16:05 t_4023239360457093510.npy\r\n","-rw-r--r-- 1 root root       95768 Apr 16 04:45 t_438455043325458450.npy\r\n","-rw-r--r-- 1 root root       95768 May 30 15:11 t_5000.npy\r\n","-rw-r--r-- 1 root root       95768 Jun  4 13:57 t_60000.npy\r\n","-rw-r--r-- 1 root root       10307 Apr 29 06:27 test_concatenate_feature.py\r\n","-rw-r--r-- 1 root root         470 Jun 14 20:42 test.py\r\n","-rw-r--r-- 1 root root        1824 Apr  3 14:08 test_Resnet50_feature.py\r\n","-rw-r--r-- 1 root root        1404 Mar 28 04:13 test_train.py\r\n","-rw-r--r-- 1 root root        7247 Mar  5 06:32 test_util.py\r\n","drwxr-xr-x 2 root root        4096 Mar  5 06:24 tmp\r\n","-rw-r--r-- 1 root root       11832 Jun 20 14:32 training_history_2\r\n","-rw-r--r-- 1 root root        1560 Jun 30 09:27 training_history_8647626824687750802\r\n","-rw-r--r-- 1 root root       11832 Jun 30 08:38 training_history_8647626824687750802 (3c704dc0)\r\n","-rw-r--r-- 1 root root        3648 Jun 28 18:41 training_history_Nthuy.pkl\r\n","-rw-r--r-- 1 root root       49791 Apr 18 17:05 Untitled0.ipynb\r\n","-rw-r--r-- 1 root root       25983 Jun 12 04:12 Untitled1.ipynb\r\n","-rw-r--r-- 1 root root        7660 Apr  3 04:05 util2.py\r\n","-rw-r--r-- 1 root root        7680 Jun 20 07:15 util.py\r\n","-rw-r--r-- 1 root root        8436 Jun 20 07:15 util.pyc\r\n","-rw-r--r-- 1 root root           0 May  6 13:20 X_200000000000_0.npy\r\n","-rw-r--r-- 1 root root    50456672 May  2 03:37 X_200000000000_1.hdf5\r\n","-rw-r--r-- 1 root root           0 May  6 13:20 X_200000000000_1.npy\r\n","-rw-r--r-- 1 root root           0 May  6 13:20 X_200000000000_2.npy\r\n","-rw-r--r-- 1 root root           0 May  6 13:20 X_200000000000_3.npy\r\n","-rw-r--r-- 1 root root         800 May  4 03:48 X_200000000000.hdf5\r\n","-rw-r--r-- 1 root root  8397959168 Jun 14 23:28 X_24081909.hdf5\r\n","-rw-r--r-- 1 root root  3847397472 Jun 13 11:25 X_2408.hdf5\r\n","-rw-r--r-- 1 root root  1371095168 Apr  9 06:12 X_2912102996873951606.npy\r\n","-rw-r--r-- 1 root root 23565698144 May 12 10:39 X_300000000000.hdf5\r\n","-rw-r--r-- 1 root root 43189493888 Mar 13 16:05 X_4023239360457093510.npy\r\n","-rw-r--r-- 1 root root 21594748928 Jun 17 03:25 X_4384550433254584501909.hdf5\r\n","-rw-r--r-- 1 root root 21595466324 Apr 16 04:45 X_438455043325458450.hdf5\r\n","-rw-r--r-- 1 root root  1371095168 May 30 13:21 X_5000.npy\r\n","-rw-r--r-- 1 root root   685549664 Jun  4 13:57 X_60000.hdf5\r\n","-rw-r--r-- 1 root root        1400 Jun  4 13:51 X_6000.hdf5\r\n","-rw-r--r-- 1 root root  4081719296 Jun 28 13:23 X_train_NthuyModel.hdf5\r\n","-rw-r--r-- 1 root root  9011812352 Jun 28 21:53 X_train_NthuyModel_V2.hdf5\r\n","-rw-r--r-- 1 root root         800 Jun 28 21:53 X_val_NthuyModel_V2.hdf5\r\n","-rw-r--r-- 1 root root       95768 May  7 03:59 y_200000000000.npy\r\n","-rw-r--r-- 1 root root       95768 Apr 18 07:42 y_2223320934302811922.npy\r\n","-rw-r--r-- 1 root root       95768 Jun 12 08:10 y_2408.npy\r\n","-rw-r--r-- 1 root root       95768 Apr 18 07:42 y_2912102996873951606.npy\r\n","-rw-r--r-- 1 root root       95768 May 12 10:39 y_300000000000.npy\r\n","-rw-r--r-- 1 root root       95768 Apr 18 07:42 y_4023239360457093510.npy\r\n","-rw-r--r-- 1 root root       95768 Apr 16 04:45 y_438455043325458450.npy\r\n","-rw-r--r-- 1 root root       95768 May 30 13:21 y_5000.npy\r\n","-rw-r--r-- 1 root root       95768 Jun  4 13:57 y_60000.npy\r\n","-rw-r--r-- 1 root root       47948 May 13 21:25 y_hat_2305240994148776829.npy\r\n","-rw-r--r-- 1 root root       47948 May 10 03:02 y_hat_3277221850808793978.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 07:41 y_hat_4754952150018512305_1.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 09:08 y_hat_4754952150018512305_2.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 15:13 y_hat_4754952150018512305_3.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 16:38 y_hat_4754952150018512305_4.npy\r\n","-rw-r--r-- 1 root root       47948 May 10 02:39 y_hat_6128076522482830630.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 07:41 y_hat_776890777140245298_1.npy\r\n","-rw-r--r-- 1 root root       95768 May 12 05:44 y_hat_7949521252375334267.npy\r\n","-rw-r--r-- 1 root root       47948 May 14 04:39 y_hat_8035819618733567531.npy\r\n","-rw-r--r-- 1 root root       47948 May 14 03:57 y_hat_8143401490449226444.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 14:36 y_hat_8647626824687750802_1.npy\r\n","-rw-r--r-- 1 root root       47948 Jun 30 09:29 y_hat_8647626824687750802.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 07:41 y_hat_8841606304273805265_1.npy\r\n","-rw-r--r-- 1 root root       47948 Jun 15 01:37 y_hat_8841606304273805265_originalsize_1.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 11 13:58 y_hat_resnet50_8841606304273805265.npy\r\n","-rw-r--r-- 1 root root       47948 May 13 21:25 y_prob_2305240994148776829.npy\r\n","-rw-r--r-- 1 root root       47948 May 10 03:02 y_prob_3277221850808793978.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 07:42 y_prob_4754952150018512305_1.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 09:08 y_prob_4754952150018512305_2.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 15:13 y_prob_4754952150018512305_3.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 16:37 y_prob_4754952150018512305_4.npy\r\n","-rw-r--r-- 1 root root       47948 May 10 02:39 y_prob_6128076522482830630.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 07:42 y_prob_776890777140245298_1.npy\r\n","-rw-r--r-- 1 root root       95768 May 12 05:44 y_prob_7949521252375334267.npy\r\n","-rw-r--r-- 1 root root       47948 May 14 04:39 y_prob_8035819618733567531.npy\r\n","-rw-r--r-- 1 root root       47948 May 14 03:57 y_prob_8143401490449226444.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 14:36 y_prob_8647626824687750802_1.npy\r\n","-rw-r--r-- 1 root root       47948 Jun 30 09:29 y_prob_8647626824687750802.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 18 07:42 y_prob_8841606304273805265_1.npy\r\n","-rw-r--r-- 1 root root       47948 Jun 15 01:37 y_prob_8841606304273805265_originalsize_1.npy\r\n","-rw-r--r-- 1 root root       47948 Apr 11 13:58 y_prob_resnet50_8841606304273805265.npy\r\n","-rw-r--r-- 1 root root       54360 Jun 28 13:22 Y_train_NThuyModel.npy\r\n","-rw-r--r-- 1 root root      106704 Jun 28 21:53 Y_train_NThuyModel_V2.npy\r\n","-rw-r--r-- 1 root root       13288 Jun 28 21:53 Y_val_NThuyModel_V2.npy\r\n"],"name":"stdout"}]},{"metadata":{"id":"U9P0-Py74XPP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"a54ce04d-fc9a-4d95-f372-90eb64f7f2d0","executionInfo":{"status":"ok","timestamp":1533090852477,"user_tz":-420,"elapsed":758,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# set feature_hash and experiment_hash\n","# and the folder contains y_hat and y_prob file\n","\n","result_folder = os.path.join('results', 'alexnet_7_1___2')\n","print(\"Result folder: \", result_folder)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["('Result folder: ', 'results/alexnet_7_1___2')\n"],"name":"stdout"}]},{"metadata":{"id":"xgL1yIfRqqcb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":646},"outputId":"cc76f0d0-4011-4151-fd5e-f9efb5247346","executionInfo":{"status":"ok","timestamp":1533138014829,"user_tz":-420,"elapsed":2784,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# import library\n","!pip install tqdm\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","import argparse\n","import copy\n","import glob\n","import h5py\n","import json\n","import matplotlib.pyplot as plt\n","from multiprocessing import Pool\n","import numpy as np\n","import os\n","from render_scenes_json import RenderScenes\n","from scipy.misc import imsave, imresize\n","from scipy.ndimage import imread\n","import shutil\n","from sklearn.metrics import confusion_matrix, average_precision_score, f1_score\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","import sys\n","from tqdm import tqdm\n","import util\n","\n","#sys.path.append(\"/home/ngocthach/caffe/python\")\n","\n","########################################################################\n","# Global Variables\n","\n","DATA_PATH = 'data'                              # Where to store temporary files\n","PUBLIC_PATH = 'public'                          # Where to show graphs and diagnostics\n","EGOCENTRIC_IMAGE_FOLDER = 'egocentric_images'   # Where egocentric images are stored\n","TMP_PATH = 'tmp'  \n","\n","\n","MISTAKEN_TASK                       = True\n","WHO_TASK                            = True\n","WHEN_TASK                           = True"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python2.7/dist-packages (4.24.0)\r\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: \n","This call to matplotlib.use() has no effect because the backend has already\n","been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n","or matplotlib.backends is imported for the first time.\n","\n","The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n","  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n","    \"__main__\", fname, loader, pkg_name)\n","  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n","    exec code in run_globals\n","  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 657, in launch_instance\n","    app.initialize(argv)\n","  File \"<decorator-gen-121>\", line 2, in initialize\n","  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 87, in catch_config_error\n","    return method(app, *args, **kwargs)\n","  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 462, in initialize\n","    self.init_gui_pylab()\n","  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 403, in init_gui_pylab\n","    InteractiveShellApp.init_gui_pylab(self)\n","  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/shellapp.py\", line 213, in init_gui_pylab\n","    r = enable(key)\n","  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2950, in enable_matplotlib\n","    pt.activate_matplotlib(backend)\n","  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 309, in activate_matplotlib\n","    matplotlib.pyplot.switch_backend(backend)\n","  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n","    matplotlib.use(newbackend, warn=False, force=True)\n","  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1305, in use\n","    reload(sys.modules['matplotlib.backends'])\n","  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n","    line for line in traceback.format_stack()\n","\n","\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"metadata":{"id":"9Xp8UPB0rG3s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"d6dce6b1-35fa-4d89-f1e3-741635d2d953","executionInfo":{"status":"ok","timestamp":1532697043703,"user_tz":-420,"elapsed":878,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# set feature_hash and experiment_hash\n","# and the folder contains y_hat and y_prob file\n","\n","result_folder = os.path.join('results', 'alexnet_singlelayer')\n","print(\"Result folder: \", result_folder)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["('Result folder: ', 'results/alexnet_singlelayer')\n"],"name":"stdout"}]},{"metadata":{"id":"1yW28uudxwrN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["random_seed_balanced = 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"32WnhLl_rSi3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1154},"cellView":"both","outputId":"07e93867-8d3a-4231-f644-56bc7290bbfb","executionInfo":{"status":"ok","timestamp":1532697068196,"user_tz":-420,"elapsed":19352,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["#@title Default title text\n","#### Get train/test results ########################\n","\n","print(\"Loading file\")\n","#feature_hash = 2408\n","feature_hash = 438455043325458450\n","#feature_hash = 2408\n","experiment_hash_list = [4754952150018512305, 8647626824687750802, 8949258729311709173, 1182471099183327604]\n","experiment_hash_list = [1182471099183327604]\n","#experiment_hash_list = [8841606304273805265, 1516386097573094802, 5305626107254735877, 2983505177517327716]\n","RANDOM_SEED = -1\n","\n","\n","for experiment_hash in experiment_hash_list:\n","\n","    ####################################################################################\n","\n","    # Mistaken task:\n","    # 1. Given a character and a frame, is the character mistaken in this frame?\n","    # 2. Given a character and a scene, is the character mistaken in any frame in the scene?\n","    \n","    print(\"############################################################\")\n","    RANDOM_SEED += 1\n","    print(\"Random_seed: \", RANDOM_SEED)\n","    print(\"Feature_hash: \", feature_hash)\n","    print(\"Experiment_hash: \", experiment_hash)\n","    \n","    if MISTAKEN_TASK:\n","        print 'Mistaken task'\n","        y = np.load('y_%d.npy' % feature_hash)\n","        y_prob = np.load(os.path.join(result_folder, 'y_prob_%d.npy' % experiment_hash))\n","        t = np.load('t_%d.npy' % feature_hash)\n","        y_hat = np.load(os.path.join(result_folder, 'y_hat_%d.npy' % experiment_hash))\n","        split_mask = np.load('split_mask_%d.npy' % experiment_hash)\n","\n","        y_prob_test = y_prob[split_mask == 'test']\n","        y_train = y[split_mask == 'train']\n","        y_val = y[split_mask == 'val']\n","        y_test = y[split_mask == 'test']\n","\n","        y_train_hat = y_hat[split_mask == 'train']\n","        y_val_hat = y_hat[split_mask == 'val']\n","        y_test_hat = y_hat[split_mask == 'test']\n","\n","        t_train = t[split_mask == 'train']\n","        t_val = t[split_mask == 'val']\n","        t_test = t[split_mask == 'test']\n","        y_test_mistaken_frame_unbalanced = y_test\n","\n","        print 'Mistaken Task - single frame'\n","\n","        print 'Training Accuracy: %.3f%%' % (100.0 * util.accuracy_score(y_train, y_train_hat))\n","        print 'Confusion matrix:'\n","        print confusion_matrix(y_train, y_train_hat)\n","        print 'Accuracy vs time:', [100.0 * util.accuracy_score(y_train[t_train == i], y_train_hat[t_train == i]) for i in range(8)]\n","        print '\\n'\n","        print 'Validation Accuracy: %.3f%%' % (100.0 * util.accuracy_score(y_val, y_val_hat))\n","        print 'Confusion matrix:'\n","        print confusion_matrix(y_val, y_val_hat)\n","        print 'Accuracy vs time:', [100.0 * util.accuracy_score(y_val[t_val == i], y_val_hat[t_val == i]) for i in range(8)]\n","        print '\\n'\n","\n","        print 'Test Accuracy: %.3f%%' % (100.0 * util.accuracy_score(y_test, y_test_hat))\n","        #print 'Test F-measure:  %.3f' %f1_score(y_test, y_test_hat)\n","        print 'Confusion matrix:'\n","        print confusion_matrix(y_test, y_test_hat)\n","        print 'Accuracy vs time:', [100.0 * util.accuracy_score(y_test[t_test == i], y_test_hat[t_test == i]) for i in range(8)]\n","        print '\\n'\n","        ((y_test_hat, y_prob_test), y_test) = util.balance((y_test_hat, y_prob_test), y_test, random_seed=random_seed_balanced)\n","        y_test_mistaken_frame_balanced = y_test\n","        print 'Mistaken[frame]: Accuracy: %.3f%%' % (100.0 * util.accuracy_score(y_test, y_test_hat))\n","        #print 'Mistaken[frame] F-measure:  %.3f' %f1_score(y_test, y_test_hat)\n","        print 'Mistaken[frame]: AP: %.3f' % average_precision_score(y_test, y_prob_test)\n","        print confusion_matrix(y_test, y_test_hat)\n","        print 'Mistaken[frame]: Chance: %.3f%%' % (100.0 * np.mean(y_test == 1))\n","        print 'Mistaken[frame]: Chance AP: %.3f' % average_precision_score(y_test, np.mean(y_test) * np.ones_like(y_test))\n","        print\n","\n","        # Mistaken[scene] - given a character and a scene, is the character mistaken in any frame in the scene?\n","\n","        question_dict_filename = os.path.join(DATA_PATH, 'question_dict.json')\n","\n","        split_dict_filename = os.path.join(DATA_PATH, 'split_dict_%02d.json' % RANDOM_SEED)\n","\n","\n","        with open(split_dict_filename) as f:\n","            split_dict = json.load(f)\n","\n","        with open(question_dict_filename) as f:\n","            question_dict = json.load(f)\n","\n","        with open('concat_indices_%d.json' % feature_hash, 'rb') as f:\n","            concat_indices = json.load(f)\n","\n","\n","        val_min_predict = []\n","        val_avg_predict = []\n","        val_y = []\n","        test_min_predict = []\n","        test_avg_predict = []\n","        test_y = []\n","\n","        for frame_key in tqdm(question_dict):\n","            (scene_id, frame_index) = frame_key.split('_')\n","            frame_index = int(frame_index)\n","\n","            # We only want to loop through each scene once\n","            if frame_index != 0:\n","                continue\n","\n","            # We only want to evaluate on characters who were mistaken in every frame or correct in every frame\n","            # In the loop below, the answers for characters who are not in the frame may be incorrect.\n","            # This is OK, because in the second loop, we only look at frames whether the model made predictions (i.e. the character was present)\n","\n","            confused_dict = dict()\n","\n","            for frame_index in range(8):\n","                frame_key = '%s_%d' % (scene_id, frame_index)\n","                answer_dict_vec = question_dict[frame_key]['answers']\n","                character_vec = question_dict[frame_key]['characters']\n","                for character_name in character_vec:\n","                    key = '%s_%s_%s' % (scene_id, frame_index, character_name)\n","                    if 'Doll' in character_name and key in concat_indices:\n","                        answer_vec = []\n","                        for answer_dict in answer_dict_vec:\n","                            answer = int(answer_dict[character_name] == answer_dict['omniscient'] )\n","                            answer_vec.append(answer)\n","\n","                        if answer_vec[0] == answer_vec[1]:\n","                            confused_dict[character_name] = [answer] + confused_dict.get(character_name, [])\n","\n","\n","            for (character_name, answer_vec) in confused_dict.items():\n","                correct = min(answer_vec)\n","\n","                predict = []\n","                for frame_index in range(8):\n","                    key = '%s_%s_%s' % (scene_id, frame_index, character_name)\n","                    # A character may appear in only a subset of the 8 frames. We\n","                    # predict whether he is mistaken based on predictions from those\n","                    # frames.\n","                    if key in concat_indices:\n","                        index = concat_indices[key]\n","                        predict.append(y_prob[index])\n","\n","                assert len(predict) > 0\n","                min_predict = min(predict)\n","                avg_predict = np.mean(predict)\n","\n","                if split_dict[scene_id] == 'val':\n","                    val_min_predict.append(min_predict)\n","                    val_avg_predict.append(avg_predict)\n","                    val_y.append(correct)\n","\n","                if split_dict[scene_id] == 'test':\n","                    test_min_predict.append(min_predict)\n","                    test_avg_predict.append(avg_predict)\n","                    test_y.append(correct)\n","\n","        test_y = np.array(test_y)\n","        test_min_predict = np.array(test_min_predict)\n","        test_avg_predict = np.array(test_avg_predict)\n","        y_test_mistaken_scene_unbalanced = test_y\n","\n","        ((test_min_predict, test_avg_predict), test_y) = util.balance((test_min_predict, test_avg_predict), test_y, random_seed=random_seed_balanced)\n","        y_test_mistaken_scene_balanced = test_y\n","\n","        print confusion_matrix(test_y, test_min_predict>0.5)\n","        print 'Mistaken[scene]: Accuracy (min pool): %.3f%%' % (100.0 * util.accuracy_score(test_y, test_min_predict > 0.5))\n","        #print 'Mistaken[scene] F-measure (min pool):  %.3f'% f1_score(test_y, test_min_predict>0.5)\n","        print 'Mistaken[scene]: AP (min pool): %.3f' % average_precision_score(test_y, test_min_predict)\n","        print 'Mistaken[scene]: Accuracy (avg pool): %.3f%%' % (100.0 * util.accuracy_score(test_y, test_avg_predict > 0.5))\n","        #print 'Mistaken[scene] F-measure (avg pool):  %.3f'% f1_score(test_y, test_avg_predict>0.5)\n","        print 'Mistaken[scene]: AP (avg pool): %.3f' % average_precision_score(test_y, test_avg_predict)\n","        print confusion_matrix(test_y, test_avg_predict>0.5)\n","        print 'Mistaken[scene]: Chance: %.3f%%' % (100.0 * max(np.mean(test_y), 1 - np.mean(test_y)))\n","        print 'Mistaken[scene]: Chance AP: %.3f' % average_precision_score(test_y, np.mean(test_y) * np.ones_like(test_y))\n","        print\n","\n","\n","\n","    ####################################################################################\n","\n","\n","    if WHO_TASK:\n","        question_dict_filename = os.path.join(DATA_PATH, 'question_dict.json')\n","\n","        split_dict_filename = os.path.join(DATA_PATH, 'split_dict_%02d.json' % RANDOM_SEED)\n","\n","        y_prob = np.load(os.path.join(result_folder, 'y_prob_%d.npy' % experiment_hash))\n","\n","        with open(split_dict_filename) as f:\n","            split_dict = json.load(f)\n","\n","        with open(question_dict_filename) as f:\n","            question_dict = json.load(f)\n","\n","        with open('concat_indices_%d.json' % feature_hash, 'rb') as f:\n","            concat_indices = json.load(f)\n","\n","        # Who task for a single frame:\n","        # Given a frame with a mistaken character and a non-mistaken character, predict which character is mistaken\n","        # Note: If a frame contains more than two characters, we will compute this for all pairs of (mistaken, non-mistaken) characters in this frame\n","\n","        correct = 0\n","        incorrect = 0\n","        predict_vec = []\n","        y_vec = []\n","        for frame_key in tqdm(question_dict):\n","            (scene_id, frame_index) = frame_key.split('_')\n","            if split_dict[scene_id] == 'test':\n","                answer_dict_vec = question_dict[frame_key]['answers']\n","                answer_vec = []\n","                confused_dict = dict()\n","                for answer_dict in answer_dict_vec:\n","                    for character_name in answer_dict:\n","                        if 'Doll' in character_name:\n","                            answer = int(answer_dict[character_name] == answer_dict['omniscient'])\n","                            confused_dict[character_name] = [answer] + confused_dict.get(character_name, [])\n","                consistent_confused_dict = dict()\n","                for (character_name, answers) in confused_dict.items():\n","                    if answers[0] == answers[1]:\n","                        consistent_confused_dict[character_name] = answers[0]\n","                for (character_name_1, correct_1) in consistent_confused_dict.items():\n","                    for (character_name_2, correct_2) in consistent_confused_dict.items():\n","                        if correct_1 == 0 and correct_2 == 1:\n","                            assert character_name_1 != character_name_2\n","                            key_1 = '%s_%s_%s' % (scene_id, frame_index, character_name_1)\n","                            key_2 = '%s_%s_%s' % (scene_id, frame_index, character_name_2)\n","                            if key_1 in concat_indices and key_2 in concat_indices:\n","                                index_1 = concat_indices[key_1]\n","                                index_2 = concat_indices[key_2]\n","                                if y_prob[index_1] < y_prob[index_2]:\n","                                    correct += 1\n","                                elif y_prob[index_1] == y_prob[index_2]:\n","                                    correct += 0.5\n","                                    incorrect += 0.5\n","                                else:\n","                                    incorrect += 1\n","\n","        print 'Who[frame]: Accuracy: %.3f%%' % (100.0 * float(correct) / (correct + incorrect))\n","\n","        # Who task for a scene:\n","        # Given a scene with a mistaken character and a non-mistaken character, predict which character is mistaken\n","        # Note: If a scene contains more than two characters, we will compute this for all pairs of (mistaken, non-mistaken) characters in this scene\n","\n","        # We can aggregate predictions across frames by taking the mean or min\n","        min_correct = 0\n","        min_incorrect = 0\n","        mean_correct = 0\n","        mean_incorrect = 0\n","        for frame_key in tqdm(question_dict):\n","            (scene_id, frame_index) = frame_key.split('_')\n","            frame_index = int(frame_index)\n","\n","            # We only want to loop through each scene once\n","            if frame_index != 0:\n","                continue\n","\n","            if split_dict[scene_id] != 'test':\n","                continue\n","\n","            # Create confused dict, which says which characters are consistently confused\n","            confused_dict = dict()\n","            for frame_index in range(8):\n","                frame_key = '%s_%d' % (scene_id, frame_index)\n","                answer_dict_vec = question_dict[frame_key]['answers']\n","                character_vec = question_dict[frame_key]['characters']\n","                for character_name in character_vec:\n","                    key = '%s_%s_%s' % (scene_id, frame_index, character_name)\n","                    answer_vec = []\n","                    if 'Doll' in character_name and key in concat_indices:\n","                        for answer_dict in answer_dict_vec:\n","                            answer = int(answer_dict[character_name] == answer_dict['omniscient'])\n","                            answer_vec.append(answer)\n","                        if answer_vec[0] == answer_vec[1]:\n","                            confused_dict[character_name] = [answer] + confused_dict.get(character_name, [])\n","\n","            for (character_name_1, answers_1) in confused_dict.items():\n","                for (character_name_2, answers_2) in confused_dict.items():\n","                    correct_1 = min(answers_1)\n","                    correct_2  = min(answers_2)\n","\n","                    if correct_1 == 0 and correct_2 == 1:\n","                        predict_1 = []\n","                        predict_2 = []\n","                        for frame_index in range(8):\n","                            key_1 = '%s_%s_%s' % (scene_id, frame_index, character_name_1)\n","                            key_2 = '%s_%s_%s' % (scene_id, frame_index, character_name_2)\n","                            if key_1 in concat_indices:\n","                                index_1 = concat_indices[key_1]\n","                                predict_1.append(y_prob[index_1])\n","\n","                            if key_2 in concat_indices:\n","                                index_2 = concat_indices[key_2]\n","                                predict_2.append(y_prob[index_2])\n","\n","                        assert len(predict_1) > 0 and len(predict_2) > 0\n","                        if np.min(predict_1) < np.min(predict_2):\n","                            min_correct += 1.0\n","                        elif np.min(predict_1) == np.min(predict_2):\n","                            min_correct += 0.5\n","                            min_incorrect += 0.5\n","                        else:\n","                            min_incorrect += 1.0\n","\n","                        if np.mean(predict_1) < np.mean(predict_2):\n","                            mean_correct += 1.0\n","                        elif np.mean(predict_1) == np.mean(predict_2):\n","                            mean_correct += 0.5\n","                            mean_incorrect += 0.5\n","                        else:\n","                            mean_incorrect += 1.0\n","\n","        print 'Who[scene]: Accuracy (min pool): %.3f%%' % (100.0 * float(min_correct) / (min_correct + min_incorrect))\n","        print 'Who[scene]: Accuracy (avg pool): %.3f%%' % (100.0 * float(mean_correct) / (mean_correct + mean_incorrect))\n","\n","\n","    if WHEN_TASK:\n","        count_ambiguous = 0\n","        # Given a frame, is any character mistaken in the frame?\n","        question_dict_filename = os.path.join(DATA_PATH, 'question_dict.json')\n","\n","        split_dict_filename = os.path.join(DATA_PATH, 'split_dict_%02d.json' % RANDOM_SEED)\n","        y_prob = np.load(os.path.join(result_folder, 'y_prob_%d.npy' % experiment_hash))\n","\n","        with open(split_dict_filename) as f:\n","            split_dict = json.load(f)\n","\n","        with open(question_dict_filename) as f:\n","            question_dict = json.load(f)\n","\n","        with open('concat_indices_%d.json' % feature_hash, 'rb') as f:\n","            concat_indices = json.load(f)\n","\n","        min_predict_vec = []\n","        avg_predict_vec = []\n","        correct_vec = []\n","        for frame_key in question_dict:\n","            (scene_id, frame_index) = frame_key.split('_')\n","            frame_index = int(frame_index)\n","\n","            if split_dict[scene_id] != 'test':\n","                continue\n","\n","            # Create confused dict, which says which characters are consistently confused\n","            confused_dict = dict()\n","\n","            answer_dict_vec = question_dict[frame_key]['answers']\n","            for answer_dict in answer_dict_vec:\n","                for character_name in answer_dict:\n","                    key = '%s_%s_%s' % (scene_id, frame_index, character_name)\n","                    if 'Doll' in character_name and key in concat_indices:\n","                        answer = int(answer_dict[character_name] == answer_dict['omniscient'])\n","                        confused_dict[character_name] = [answer] + confused_dict.get(character_name, [])\n","\n","            consistent_frame = True\n","            for (character_name, answers) in confused_dict.items():\n","                if len(set(answers)) > 1:\n","                    #consistent_frame = False\n","                    #break\n","                    count_ambiguous += 1\n","                    del confused_dict[character_name]\n","\n","            if not consistent_frame or len(confused_dict.keys()) == 0:\n","                continue\n","\n","            # answer tells us whether every character is correct.\n","            # if the frame contains a consistently mistaken character (across the two annotations), answer = 0\n","            answer = min([ans for ans_vec in confused_dict.values() for ans in ans_vec])\n","            predict = []\n","\n","            for character_name in confused_dict.keys():\n","                key = '%s_%s_%s' % (scene_id, frame_index, character_name)\n","                if key in concat_indices:\n","                    index = concat_indices[key]\n","                    predict.append(y_prob[index])\n","\n","            min_predict = min(predict)\n","            avg_predict = np.mean(predict)\n","\n","\n","            min_predict_vec.append(min_predict)\n","            avg_predict_vec.append(avg_predict)\n","            correct_vec.append(answer)\n","\n","\n","        min_predict_vec = np.array(min_predict_vec)\n","        avg_predict_vec = np.array(avg_predict_vec)\n","        correct_vec = np.array(correct_vec)\n","        y_test_when_unbalanced = correct_vec\n","\n","        ((min_predict_vec, avg_predict_vec), correct_vec) = util.balance((min_predict_vec, avg_predict_vec), correct_vec, random_seed=random_seed_balanced)\n","        y_test_when_balanced = correct_vec\n","        print(\"Ambiguous: \", count_ambiguous)\n","        print confusion_matrix(correct_vec, min_predict_vec >0.5)\n","        print 'When: Accuracy (min pool): %.3f%%' % (100.0 * util.accuracy_score(correct_vec, min_predict_vec > 0.5))\n","        #print 'Mistaken[scene] F-measure (min pool):  %.3f' %f1_score(correct_vec, min_predict_vec >0.5)\n","        print 'When: AP (min pool): %.3f' % average_precision_score(correct_vec, min_predict_vec)\n","        print 'When: Accuracy (avg pool): %.3f%%' % (100.0 * util.accuracy_score(correct_vec, avg_predict_vec > 0.5))\n","        print 'When: AP (avg pool): %.3f' % average_precision_score(correct_vec, avg_predict_vec)\n","        print confusion_matrix(correct_vec, avg_predict_vec >0.5)\n","        #print 'When F-measure (avg pool):  %.3f'% f1_score(correct_vec, avg_predict_vec >0.5)\n","        print 'When: Chance: %.3f%%' % (100.0 * np.mean(correct_vec))\n","        print 'When: Chance AP: %.3f' % average_precision_score(correct_vec, np.mean(correct_vec) * np.ones_like(correct_vec))\n","\n","\n","    ########################################################################\n","    # Cleanup\n","\n","print 'Cleaning up'"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Loading file\n","############################################################\n","('Random_seed: ', 0)\n","('Feature_hash: ', 438455043325458450)\n","('Experiment_hash: ', 1182471099183327604)\n","Mistaken task\n","Mistaken Task - single frame\n","Training Accuracy: 70.983%\n","Confusion matrix:\n","[[1788  443]\n"," [2356 5059]]\n","Accuracy vs time: [84.86486486486487, 85.20710059171599, 77.53378378378379, 60.1063829787234, 60.2224123182207, 54.6462063086104, 56.91244239631337, 86.97208303507516]\n","\n","\n","Validation Accuracy: 65.802%\n","Confusion matrix:\n","[[216  82]\n"," [287 494]]\n","Accuracy vs time: [79.82456140350878, 80.0, 70.22900763358778, 62.22222222222222, 51.14503816793893, 51.449275362318836, 54.861111111111114, 78.2051282051282]\n","\n","\n","Test Accuracy: 66.098%\n","Confusion matrix:\n","[[202  96]\n"," [321 611]]\n","Accuracy vs time: [84.02777777777779, 77.27272727272727, 66.66666666666666, 53.284671532846716, 47.682119205298015, 51.92307692307693, 59.523809523809526, 85.79545454545455]\n","\n","\n","Mistaken[frame]: Accuracy: 66.416%\n","Mistaken[frame]: AP: 0.683\n","[[627 305]\n"," [321 611]]\n","Mistaken[frame]: Chance: 50.000%\n","Mistaken[frame]: Chance AP: 0.500\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 9704/9704 [00:00<00:00, 36477.80it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["[[109   8]\n"," [ 73  44]]\n","Mistaken[scene]: Accuracy (min pool): 65.385%\n","Mistaken[scene]: AP (min pool): 0.805\n","Mistaken[scene]: Accuracy (avg pool): 72.650%\n","Mistaken[scene]: AP (avg pool): 0.762\n","[[79 38]\n"," [26 91]]\n","Mistaken[scene]: Chance: 50.000%\n","Mistaken[scene]: Chance AP: 0.500\n","\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 9704/9704 [00:00<00:00, 273745.16it/s]\n","100%|██████████| 9704/9704 [00:00<00:00, 158313.79it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Who[frame]: Accuracy: 87.770%\n","Who[scene]: Accuracy (min pool): 80.000%\n","Who[scene]: Accuracy (avg pool): 80.000%\n","('Ambiguous: ', 0)\n","[[464  81]\n"," [205 340]]\n","When: Accuracy (min pool): 73.761%\n","When: AP (min pool): 0.841\n","When: Accuracy (avg pool): 72.661%\n","When: AP (avg pool): 0.807\n","[[409 136]\n"," [162 383]]\n","When: Chance: 50.000%\n","When: Chance AP: 0.500\n","Cleaning up\n"],"name":"stdout"}]},{"metadata":{"id":"hV7LtM5Aicpu","colab_type":"text"},"cell_type":"markdown","source":["Load model"]},{"metadata":{"id":"DI6WyzZJdAbU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"6af11c4e-38ca-4641-ec7e-c48e7a57fbf7","executionInfo":{"status":"ok","timestamp":1533090856740,"user_tz":-420,"elapsed":594,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# set feature_hash and experiment_hash\n","# and the folder contains y_hat and y_prob file\n","\n","experiment_hash = 4754952150018512305\n","\n","result_folder = os.path.join('results', 'alexnet_14_7_1')\n","print(\"Result folder: \", result_folder)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["('Result folder: ', 'results/alexnet_14_7_1')\n"],"name":"stdout"}]},{"metadata":{"id":"HHc5HlADdkDH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K0_RleRjd23E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":256},"outputId":"726cfcdc-7e77-4cad-d1f1-8a2c3445066b","executionInfo":{"status":"error","timestamp":1533090862500,"user_tz":-420,"elapsed":3965,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["#experiment_hash_list = [4754952150018512305, 8647626824687750802, 8949258729311709173, 1182471099183327604]\n","experiment_hash_list = [8647626824687750802, 8949258729311709173, 1182471099183327604]\n","for experiment_hash in experiment_hash_list:\n","  with open(os.path.join(result_folder, 'training_history_%d'%experiment_hash), mode='rb') as file_history:\n","    history = pickle.load(file_history)\n","\n","    print(history.keys())\n","    # summarize history for accuracy\n","    plt.plot(history['acc'])\n","    plt.plot(history['val_acc'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","    # summarize history for loss\n","    plt.plot(history['loss'])\n","    plt.plot(history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    plt.show()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['acc', 'loss', 'val_acc', 'val_loss']\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-7-3189e134ce1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"metadata":{"id":"evGRPaHNeP79","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"438c41ff-831e-4691-82ed-ee6041b50b48","executionInfo":{"status":"ok","timestamp":1532697106587,"user_tz":-420,"elapsed":922,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["sum(test_avg_predict > 0.5)/float(len(test_avg_predict))"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5512820512820513"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"UvDm5M-1PdLx","colab_type":"text"},"cell_type":"markdown","source":["Evaluate train/test"]},{"metadata":{"id":"ubbpjoO3Pf7B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def evaluate_test(y_test):\n","  print(\"Len: \", len(y_test))\n","  print(\"#mistaken: \", sum(y_test==0))\n","  print(\"Mistaken %: \", sum(y_test==0)/float(len(y_test)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"___r5MT1P0sS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["y_test_dict = {\n","    'mistaken_frame_unbalanced': y_test_mistaken_frame_unbalanced,\n","    'mistaken_frame_balanced': y_test_mistaken_frame_balanced,\n","    'mistaken_scene_unbalanced': y_test_mistaken_scene_unbalanced,\n","    'mistaken_scene_balanced': y_test_mistaken_scene_balanced,\n","    'when_unbalacned': y_test_when_unbalanced, \n","    'when_balanced': y_test_when_balanced\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_Us4hpnQQQvJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":443},"outputId":"483613a0-ca9b-4e60-e45d-f64a58afc823","executionInfo":{"status":"ok","timestamp":1532697112764,"user_tz":-420,"elapsed":580,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["for (key, value) in y_test_dict.items():\n","  print(key)\n","  evaluate_test(value)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["mistaken_scene_balanced\n","('Len: ', 234)\n","('#mistaken: ', 117)\n","('Mistaken %: ', 0.5)\n","mistaken_scene_unbalanced\n","('Len: ', 232)\n","('#mistaken: ', 117)\n","('Mistaken %: ', 0.5043103448275862)\n","mistaken_frame_unbalanced\n","('Len: ', 1230)\n","('#mistaken: ', 298)\n","('Mistaken %: ', 0.24227642276422764)\n","when_balanced\n","('Len: ', 1090)\n","('#mistaken: ', 545)\n","('Mistaken %: ', 0.5)\n","mistaken_frame_balanced\n","('Len: ', 1864)\n","('#mistaken: ', 932)\n","('Mistaken %: ', 0.5)\n","when_unbalacned\n","('Len: ', 759)\n","('#mistaken: ', 214)\n","('Mistaken %: ', 0.28194993412384717)\n"],"name":"stdout"}]},{"metadata":{"id":"sQpJPcK4Q-J5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["split_dict_filename = os.path.join(DATA_PATH, 'split_dict_00.json')\n","with open(split_dict_filename) as f:\n","    split_dict = json.load(f)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wbtxT3hUVYJi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"fc223630-27a6-425c-cb57-996e9a6ca575","executionInfo":{"status":"ok","timestamp":1532697124158,"user_tz":-420,"elapsed":1021,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["splitA = {'train':0, 'test':0, 'val':0, 'other':0}\n","for (key, value) in split_dict.items():\n","  if value in ['train', 'val', 'test']:\n","    splitA[value] += 1\n","  else:\n","    splitA['other'] += 1\n","\n","print(splitA)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["{'test': 122, 'train': 970, 'other': 0, 'val': 121}\n"],"name":"stdout"}]},{"metadata":{"id":"Rap7xGwrSUbV","colab_type":"text"},"cell_type":"markdown","source":["Evaluate the prediction of muliple models"]},{"metadata":{"id":"FyzLA0j1U2Ga","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"13e1e101-3f30-492d-bd46-2a9017aded70","executionInfo":{"status":"ok","timestamp":1533138036243,"user_tz":-420,"elapsed":705,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["feature_hash = 438455043325458450\n","experiment_hash = 8647626824687750802\n","\n","# set feature_hash and experiment_hash\n","# and the folder contains y_hat and y_prob file\n","\n","result_folder = 'results'\n","print(\"Result folder: \", result_folder)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["('Result folder: ', 'results')\n"],"name":"stdout"}]},{"metadata":{"id":"UxYyTRRJVcpw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["list_model = ['alexnet_singlelayer', 'alexnet_4_1', 'alexnet_7_1', 'alexnet_11_1', 'alexnet_15_1', 'alexnet_7_3_1', 'alexnet_14_7_1']\n","\n","# read y test\n","y = np.load('y_%d.npy' % feature_hash)\n","\n","y_dict = {'correct_label': y}\n","\n","\n","# read y_hat and y_prob of each model\n","\n","for model in list_model:\n","  result_folder_temp = os.path.join(result_folder, model)\n","  y_prob = np.load(os.path.join(result_folder_temp,'y_prob_%d.npy' % experiment_hash))\n","  y_hat = np.load(os.path.join(result_folder_temp,'y_hat_%d.npy' % experiment_hash))\n","  \n","  y_dict[model] = {'y_hat':y_hat, 'y_prob': y_prob}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VXsUWv4jTu6P","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","split_mask = np.load('split_mask_%d.npy' % experiment_hash)\n","prediction_dict = {}\n","for model in list_model:\n","  prediction_dict[model] = {'correct_mistaken': [], 'wrong_mistaken':[], 'correct_non_mistaken': [], 'wrong_non_mistaken': []}\n","\n","# read concat_indices file\n","with open('concat_indices_%d.json' % feature_hash, 'rb') as f:\n","    concat_indices = json.load(f)\n","    \n","for (scene_frame_character, index) in concat_indices.items():\n","  \n","  # check if index is for test set\n","  if split_mask[index] != 'test':\n","    continue\n","  \n","  for model in list_model:\n","    if y_dict['correct_label'][index] == 0:\n","      \n","      if y_dict['correct_label'][index] == y_dict[model]['y_hat'][index]:\n","        prediction_dict[model]['correct_mistaken'].append(scene_frame_character)\n","      else:\n","        prediction_dict[model]['wrong_mistaken'].append(scene_frame_character)\n","        \n","    elif y_dict['correct_label'][index] == 1:\n","      \n","      if y_dict['correct_label'][index] == y_dict[model]['y_hat'][index]:\n","        prediction_dict[model]['correct_non_mistaken'].append(scene_frame_character)\n","      else:\n","        prediction_dict[model]['wrong_non_mistaken'].append(scene_frame_character)\n","      \n","      "],"execution_count":0,"outputs":[]},{"metadata":{"id":"qjenFc4iZL3n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":612},"outputId":"dd4ceed8-002d-4ac4-d157-f1e3028a22e0","executionInfo":{"status":"ok","timestamp":1533138045509,"user_tz":-420,"elapsed":620,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["for model in list_model:\n","  print(\"Model: \", model)\n","  print(\"#Wrong mistaken: \", len(prediction_dict[model]['wrong_mistaken']))\n","  print(\"#Correct mistaken: \", len(prediction_dict[model]['correct_mistaken']))\n","  print(\"#Wrong non mistaken: \", len(prediction_dict[model]['wrong_non_mistaken']))\n","  print(\"#Correct non mistaken: \", len(prediction_dict[model]['correct_non_mistaken']))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["('Model: ', 'alexnet_singlelayer')\n","('#Wrong mistaken: ', 98)\n","('#Correct mistaken: ', 193)\n","('#Wrong non mistaken: ', 302)\n","('#Correct non mistaken: ', 557)\n","('Model: ', 'alexnet_4_1')\n","('#Wrong mistaken: ', 122)\n","('#Correct mistaken: ', 169)\n","('#Wrong non mistaken: ', 201)\n","('#Correct non mistaken: ', 658)\n","('Model: ', 'alexnet_7_1')\n","('#Wrong mistaken: ', 80)\n","('#Correct mistaken: ', 211)\n","('#Wrong non mistaken: ', 305)\n","('#Correct non mistaken: ', 554)\n","('Model: ', 'alexnet_11_1')\n","('#Wrong mistaken: ', 137)\n","('#Correct mistaken: ', 154)\n","('#Wrong non mistaken: ', 168)\n","('#Correct non mistaken: ', 691)\n","('Model: ', 'alexnet_15_1')\n","('#Wrong mistaken: ', 128)\n","('#Correct mistaken: ', 163)\n","('#Wrong non mistaken: ', 179)\n","('#Correct non mistaken: ', 680)\n","('Model: ', 'alexnet_7_3_1')\n","('#Wrong mistaken: ', 156)\n","('#Correct mistaken: ', 135)\n","('#Wrong non mistaken: ', 127)\n","('#Correct non mistaken: ', 732)\n","('Model: ', 'alexnet_14_7_1')\n","('#Wrong mistaken: ', 3)\n","('#Correct mistaken: ', 288)\n","('#Wrong non mistaken: ', 813)\n","('#Correct non mistaken: ', 46)\n"],"name":"stdout"}]},{"metadata":{"id":"JKyQtgpEZZlo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1343},"outputId":"e1cf7c61-e59c-44e1-aa5d-9038b8783f2b","executionInfo":{"status":"ok","timestamp":1533138047344,"user_tz":-420,"elapsed":684,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# compare prediction class of baseline vs model 7_1 \n","\n","\n","comparison_dict = {'all_correct': {}, 'all_wrong': {}, 'alexnet_singlelayer_correct': {}, model: {}}\n","for model in list_model:\n","  \n","  if model == 'alexnet_singlelayer':\n","    continue\n","\n","\n","  comparison_dict['all_correct'] = {'mistaken': [], 'non_mistaken':[]}\n","  comparison_dict['all_wrong'] = {'mistaken': [], 'non_mistaken':[]}\n","  comparison_dict['alexnet_singlelayer_correct'] = {'mistaken': [], 'non_mistaken':[]}\n","  comparison_dict[model] = {'mistaken': [], 'non_mistaken':[]}\n","\n","  comparison_dict['all_correct']['mistaken'] = set(prediction_dict['alexnet_singlelayer']['correct_mistaken']).intersection(prediction_dict[model]['correct_mistaken'])\n","  comparison_dict['all_correct']['non_mistaken'] = set(prediction_dict['alexnet_singlelayer']['correct_non_mistaken']).intersection(prediction_dict[model]['correct_non_mistaken'])\n","\n","  comparison_dict['all_wrong']['mistaken'] = set(prediction_dict['alexnet_singlelayer']['wrong_mistaken']).intersection(prediction_dict[model]['wrong_mistaken'])\n","  comparison_dict['all_wrong']['non_mistaken'] = set(prediction_dict['alexnet_singlelayer']['wrong_non_mistaken']).intersection(prediction_dict[model]['wrong_non_mistaken'])\n","\n","  comparison_dict['alexnet_singlelayer_correct']['mistaken'] = set(prediction_dict['alexnet_singlelayer']['correct_mistaken'])- set(prediction_dict[model]['correct_mistaken'])\n","  comparison_dict['alexnet_singlelayer_correct']['non_mistaken'] = set(prediction_dict['alexnet_singlelayer']['correct_non_mistaken'])- set(prediction_dict[model]['correct_non_mistaken'])\n","\n","  comparison_dict[model]['mistaken'] = set(prediction_dict[model]['correct_mistaken'])- set(prediction_dict['alexnet_singlelayer']['correct_mistaken'])\n","  comparison_dict[model]['non_mistaken'] = set(prediction_dict[model]['correct_non_mistaken'])- set(prediction_dict['alexnet_singlelayer']['correct_non_mistaken'])\n","  \n","  # print result\n","  print(\"Alexnet_singlelayer vs \", model)\n","  \n","  for (term, value) in comparison_dict.items():\n","    if term in list_model and term not in ['alexnet_singlelayer', model]:\n","      continue\n","    print(term, \": \")\n","  \n","    for (item, v) in value.items():\n","      print(item, \": \", len(v))\n","\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["('Alexnet_singlelayer vs ', 'alexnet_4_1')\n","('alexnet_4_1', ': ')\n","('non_mistaken', ': ', 141)\n","('mistaken', ': ', 15)\n","('all_wrong', ': ')\n","('non_mistaken', ': ', 161)\n","('mistaken', ': ', 83)\n","('all_correct', ': ')\n","('non_mistaken', ': ', 517)\n","('mistaken', ': ', 154)\n","('alexnet_singlelayer_correct', ': ')\n","('non_mistaken', ': ', 40)\n","('mistaken', ': ', 39)\n","('Alexnet_singlelayer vs ', 'alexnet_7_1')\n","('alexnet_7_1', ': ')\n","('non_mistaken', ': ', 87)\n","('mistaken', ': ', 37)\n","('alexnet_singlelayer_correct', ': ')\n","('non_mistaken', ': ', 90)\n","('mistaken', ': ', 19)\n","('all_wrong', ': ')\n","('non_mistaken', ': ', 215)\n","('mistaken', ': ', 61)\n","('all_correct', ': ')\n","('non_mistaken', ': ', 467)\n","('mistaken', ': ', 174)\n","('Alexnet_singlelayer vs ', 'alexnet_11_1')\n","('alexnet_singlelayer_correct', ': ')\n","('non_mistaken', ': ', 25)\n","('mistaken', ': ', 46)\n","('alexnet_11_1', ': ')\n","('non_mistaken', ': ', 159)\n","('mistaken', ': ', 7)\n","('all_wrong', ': ')\n","('non_mistaken', ': ', 143)\n","('mistaken', ': ', 91)\n","('all_correct', ': ')\n","('non_mistaken', ': ', 532)\n","('mistaken', ': ', 147)\n","('Alexnet_singlelayer vs ', 'alexnet_15_1')\n","('alexnet_15_1', ': ')\n","('non_mistaken', ': ', 157)\n","('mistaken', ': ', 14)\n","('alexnet_singlelayer_correct', ': ')\n","('non_mistaken', ': ', 34)\n","('mistaken', ': ', 44)\n","('all_wrong', ': ')\n","('non_mistaken', ': ', 145)\n","('mistaken', ': ', 84)\n","('all_correct', ': ')\n","('non_mistaken', ': ', 523)\n","('mistaken', ': ', 149)\n","('Alexnet_singlelayer vs ', 'alexnet_7_3_1')\n","('alexnet_singlelayer_correct', ': ')\n","('non_mistaken', ': ', 25)\n","('mistaken', ': ', 68)\n","('alexnet_7_3_1', ': ')\n","('non_mistaken', ': ', 200)\n","('mistaken', ': ', 10)\n","('all_wrong', ': ')\n","('non_mistaken', ': ', 102)\n","('mistaken', ': ', 88)\n","('all_correct', ': ')\n","('non_mistaken', ': ', 532)\n","('mistaken', ': ', 125)\n","('Alexnet_singlelayer vs ', 'alexnet_14_7_1')\n","('alexnet_singlelayer_correct', ': ')\n","('non_mistaken', ': ', 517)\n","('mistaken', ': ', 1)\n","('all_wrong', ': ')\n","('non_mistaken', ': ', 296)\n","('mistaken', ': ', 2)\n","('alexnet_14_7_1', ': ')\n","('non_mistaken', ': ', 6)\n","('mistaken', ': ', 96)\n","('all_correct', ': ')\n","('non_mistaken', ': ', 40)\n","('mistaken', ': ', 192)\n"],"name":"stdout"}]},{"metadata":{"id":"BNzXmqEPdPYO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":272},"outputId":"c5aa721c-9c5e-4c0b-9208-65968b10008a","executionInfo":{"status":"ok","timestamp":1533138050974,"user_tz":-420,"elapsed":624,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":[" comparison_dict['alexnet_4_1']['mistaken']"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{u'31QNSG6A5RSC86TKB0AQA3MDLPD87S_5_Doll03',\n"," u'31QNSG6A5RSC86TKB0AQA3MDLPD87S_6_Doll06',\n"," u'31T4R4OBOSFEK9JXSCQVCPIWF23C7J_4_Doll15',\n"," u'31T4R4OBOSFEK9JXSCQVCPIWF23C7J_5_Doll15',\n"," u'34Q075JO1XCGFV9FRGG2GEPI2G210R_4_Doll15',\n"," u'3B4YI393V9VGAOSLD1E6MLIANT1SSY_2_Doll01',\n"," u'3I7DHKZYGNZ60HPOVL1ZMBP3KKI5FB_5_Doll18',\n"," u'3IRIK4HM3AJVG95S92L36BI0HEZ6C1_5_Doll15',\n"," u'3MMN5BL1WZ39SCU13PHJ24BS3N2M34_3_Doll11',\n"," u'3NC5L260MOLS8RV600XYVHPU1MSFO9_6_Doll04',\n"," u'3OLF68YTN9036N15QHSGUM5PC30FAI_5_Doll16',\n"," u'3X4JMASXCM8HSTR7TD9RMQ2RLPZ0B6_6_Doll04',\n"," u'3X4JMASXCM8HSTR7TD9RMQ2RQWS0BI_0_Doll17',\n"," u'3X4JMASXCM8HSTR7TD9RMQ2RQWS0BI_4_Doll17',\n"," u'3ZAK8W07I4DWOS0DT4QMRGUFDO10UD_4_Doll15'}"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"BVnft3q9eK0M","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"X09GTseEljQU","colab_type":"text"},"cell_type":"markdown","source":["Get prediction of multiple model in a scene:"]},{"metadata":{"id":"VlrOkCpkj4f2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":427},"outputId":"86c1ee5c-6510-41e4-9080-cc2dac5b06d0","executionInfo":{"status":"ok","timestamp":1532697762206,"user_tz":-420,"elapsed":1482,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["# read file concate_indices:\n","\n","scene_id = '3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H'\n","\n","model_prediction = {}\n","for (scene_frame_character, index) in concat_indices.items():\n","\n","  # check if index is for test set\n","  if split_mask[index] != 'test':\n","    continue\n","    \n","  if scene_id not in scene_frame_character:\n","    continue\n","  \n","  model_prediction[scene_frame_character] = {}\n","  model_prediction[scene_frame_character]['correct'] = y_dict['correct_label'][index]\n","  for model in list_model:\n","    model_prediction[scene_frame_character][model] = (int(y_dict[model]['y_hat'][index])== y_dict['correct_label'][index], round(float(y_dict[model]['y_prob'][index]), 3))\n","      \n","\n","for (scene_frame_character, value) in model_prediction.items():\n","  print(scene_frame_character)\n","  print(value)\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_6_Doll18\n","{'alexnet_15_1': (True, 0.425), 'alexnet_11_1': (True, 0.437), 'alexnet_singlelayer': (False, 0.951), 'alexnet_7_1___2': (True, 0.443), 'alexnet_4_1': (True, 0.439), 'alexnet_7_3_1': (True, 0.384), 'alexnet_14_7_1': (True, 0.49), 'correct': 0}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_2_Doll06\n","{'alexnet_15_1': (True, 0.718), 'alexnet_11_1': (True, 0.73), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.743), 'alexnet_4_1': (True, 0.73), 'alexnet_7_3_1': (True, 0.544), 'alexnet_14_7_1': (True, 0.528), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_5_Doll17\n","{'alexnet_15_1': (True, 0.723), 'alexnet_11_1': (True, 0.726), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.746), 'alexnet_4_1': (True, 0.764), 'alexnet_7_3_1': (True, 0.543), 'alexnet_14_7_1': (True, 0.522), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_0_Doll18\n","{'alexnet_15_1': (True, 0.604), 'alexnet_11_1': (True, 0.61), 'alexnet_singlelayer': (False, 0.303), 'alexnet_7_1___2': (True, 0.63), 'alexnet_4_1': (True, 0.648), 'alexnet_7_3_1': (False, 0.483), 'alexnet_14_7_1': (True, 0.508), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_3_Doll18\n","{'alexnet_15_1': (True, 0.523), 'alexnet_11_1': (True, 0.546), 'alexnet_singlelayer': (True, 0.988), 'alexnet_7_1___2': (True, 0.569), 'alexnet_4_1': (True, 0.587), 'alexnet_7_3_1': (False, 0.403), 'alexnet_14_7_1': (False, 0.494), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_1_Doll06\n","{'alexnet_15_1': (True, 0.704), 'alexnet_11_1': (True, 0.735), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.771), 'alexnet_4_1': (True, 0.804), 'alexnet_7_3_1': (True, 0.543), 'alexnet_14_7_1': (True, 0.514), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_1_Doll18\n","{'alexnet_15_1': (True, 0.67), 'alexnet_11_1': (True, 0.687), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.708), 'alexnet_4_1': (True, 0.724), 'alexnet_7_3_1': (True, 0.501), 'alexnet_14_7_1': (True, 0.519), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_4_Doll18\n","{'alexnet_15_1': (False, 0.402), 'alexnet_11_1': (False, 0.409), 'alexnet_singlelayer': (False, 0.0), 'alexnet_7_1___2': (False, 0.422), 'alexnet_4_1': (False, 0.425), 'alexnet_7_3_1': (False, 0.343), 'alexnet_14_7_1': (False, 0.485), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_2_Doll18\n","{'alexnet_15_1': (True, 0.667), 'alexnet_11_1': (True, 0.699), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.73), 'alexnet_4_1': (True, 0.764), 'alexnet_7_3_1': (False, 0.483), 'alexnet_14_7_1': (True, 0.512), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_3_Doll06\n","{'alexnet_15_1': (True, 0.716), 'alexnet_11_1': (True, 0.785), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.788), 'alexnet_4_1': (True, 0.836), 'alexnet_7_3_1': (True, 0.543), 'alexnet_14_7_1': (True, 0.518), 'correct': 1}\n","3CN4LGXD5XNU4P2JM6AD64Q5QMOY4H_6_Doll17\n","{'alexnet_15_1': (True, 0.732), 'alexnet_11_1': (True, 0.758), 'alexnet_singlelayer': (True, 1.0), 'alexnet_7_1___2': (True, 0.743), 'alexnet_4_1': (True, 0.768), 'alexnet_7_3_1': (True, 0.544), 'alexnet_14_7_1': (True, 0.532), 'correct': 1}\n"],"name":"stdout"}]},{"metadata":{"id":"8zP2DWcWnEWe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"MtUfyNyJrIKM","colab_type":"text"},"cell_type":"markdown","source":["**Extract scene description from scene json file**"]},{"metadata":{"id":"9RPCNtWOrLrz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# load scene file\n","# load json file\n","with open(\"data/scenes.json\") as file:\n","    scenes = json.load(file)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QNk4hxtcrMRT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["scene_dict_description = {}\n","for scene in scenes:\n","  scene_dict_description[scene['assignmentId']] = scene['hitDescription']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"85X89e03s4qq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"b207d6d1-af64-42ad-c978-c6eb7a22edb6","executionInfo":{"status":"ok","timestamp":1532711409898,"user_tz":-420,"elapsed":756,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":[")scene_dict_description)"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1213"]},"metadata":{"tags":[]},"execution_count":74}]},{"metadata":{"id":"uaSZlzabuBWQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"3580c52b-5807-4f61-8e94-2b480b901707","executionInfo":{"status":"ok","timestamp":1532711745146,"user_tz":-420,"elapsed":845,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["for (key, value) in scene_dict_description.items()[:1]:\n","  print(key, value)"],"execution_count":78,"outputs":[{"output_type":"stream","text":["(u'3L4PIM1GQTF15V4HXI6QEX1FFNDYRC', u'{\"scene_description\":\"The man thought he would be done barbequeing before dark.\",\"frame_description\":[\"A man prepares to BBQ.\",\"The man struggles to get the flame started and gets frustrated.\",\"The man decides to make a campfire in frustration.\",\"The man grabs his plates of meat.\",\"He places the meat on the flames.\",\"The man sits down to wait for his meat to cook.\",\"The man checks on his meat on the pit and sees it is cooking too slowly.\",\"The man packs up his stuff and goes home in frustration.\"]}')\n"],"name":"stdout"}]},{"metadata":{"id":"AYTETP3UuH9g","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}