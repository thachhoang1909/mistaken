{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"yz3OKxtRRwno","colab_type":"text"},"cell_type":"markdown","source":["- Mount Google Drive to project location"]},{"metadata":{"id":"8e23hXgdRwnq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["client_id=359149138727-qjpk3tdnud9chmb8vqc5a5t1n633r8me.apps.googleusercontent.com\n","client_secret=4nTH7qUwCeZ_Q8KeuuhagASy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cib8jrbTRwnt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":56},"outputId":"fb604baf-0e84-4e1b-cdd3-0ebdb87f6a08"},"cell_type":"code","source":["import getpass\n","!google-drive-ocamlfuse -headless -label me -id {client_id} -secret {client_secret}\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -label me -id {client_id} -secret {client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/bin/sh: 1: google-drive-ocamlfuse: not found\r\n"],"name":"stdout"}]},{"metadata":{"id":"jVcJK-bzRwnw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"92419453-7c61-4b48-a804-84e3c98a0f67"},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n"],"name":"stdout"}]},{"metadata":{"id":"4xylqoetRwn1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"05f6f1db-6a2a-4f17-e8f3-cf140ee5e438","executionInfo":{"status":"ok","timestamp":1520839084667,"user_tz":-420,"elapsed":5725,"user":{"displayName":"Thúy Lê Thị Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"107045413689643894766"}}},"cell_type":"code","source":["google-drive-ocamlfuse -headless -label me -id 359149138727-qjpk3tdnud9chmb8vqc5a5t1n633r8me.apps.googleusercontent.com -secret 4nTH7qUwCeZ_Q8KeuuhagASy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["datalab\r\n"],"name":"stdout"}]},{"metadata":{"id":"_G5Zl1eyRwn5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"5f515436-fad2-4719-8a57-58ea8cf3c19e"},"cell_type":"code","source":["import os\n","os.chdir('drive')\n","os.chdir('mistaken')\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["afs\t\t\t   drive\t\t  render_scenes_json.pyc\n","analysis_data.ipynb\t   egocentric_images\t  run_test.ipynb\n","big_living_background.png  living_bg1.png\t  test_util.py\n","big_park_background.png    mistaken.py\t\t  tmp\n","caffe\t\t\t   park_bg1.png\t\t  util.py\n","convSVM\t\t\t   public\t\t  util.pyc\n","data\t\t\t   render_scenes_json.py\n"],"name":"stdout"}]},{"metadata":{"id":"5Es18e3eRwn7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"640e6701-e17f-409c-ed4b-b61059a09797"},"cell_type":"code","source":["import util\n","import json\n","import matplotlib\n","#matplotlib.use('Agg')\n","import argparse\n","import copy\n","import glob\n","import h5py\n","import matplotlib.pyplot as plt\n","from multiprocessing import Pool\n","import numpy as np\n","from scipy.misc import imsave, imresize\n","from scipy.ndimage import imread\n","import os\n","from tqdm import tqdm"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/home/drsung2410/mistaken/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n"],"name":"stderr"}]},{"metadata":{"id":"0o3YUKIKRwn-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["DATA_PATH = 'data'                              # Where to store temporary files\n","PUBLIC_PATH = 'public'                          # Where to show graphs and diagnostics\n","EGOCENTRIC_IMAGE_FOLDER = 'egocentric_images'   # Where egocentric images are stored\n","TMP_PATH = 'tmp'  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zS_GdETPRwoA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"5f4a0c3c-2a77-404f-b958-9df858b7d235"},"cell_type":"code","source":["CHECK_IMAGE_FEATURES = True\n","if CHECK_IMAGE_FEATURES:\n","    print 'Checking image features'\n","    frame_dict_filename = os.path.join(DATA_PATH, 'frame_dict_cnn.json')\n","    image_features_filename = os.path.join(DATA_PATH, 'egocentric_image_features.npy')\n","    X = np.load(image_features_filename)\n","\n","    with open(frame_dict_filename) as f:\n","        frame_dict = json.load(f)\n","    \n","    inverse_frame_dict = {feature_index: scene_frame_char for (scene_frame_char, feature_index) in frame_dict.items()}\n","\n","    index = 0\n","    diff = np.sum((X - X[[index], :])**2, axis=1)\n","    indices = np.argsort(diff)\n","    print indices[:10]\n","    \n","    for i in range(0, 100, 10):\n","        feature_index = indices[i]\n","        scene_frame_char = inverse_frame_dict[feature_index]\n","        print scene_frame_char\n","        img_filename = os.path.join(EGOCENTRIC_IMAGE_FOLDER, '%s.png' % scene_frame_char)\n","        new_img_filename = os.path.join(PUBLIC_PATH, 'retrieve_1000_%05d.png' % i)\n","        shutil.copy(img_filename, new_img_filename)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Checking image features\n"],"name":"stdout"},{"output_type":"error","ename":"MemoryError","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-acc7b0f84ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMemoryError\u001b[0m: "]}]},{"metadata":{"id":"EilQ-56dRwoD","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"562d1a02-274b-4844-934c-4c888021c8c9"},"cell_type":"code","source":["# Train/Test splits\n","# Create a dictionary which maps scene_ids to 'train' or 'test'\n","MAKE_SPLITS = True\n","if MAKE_SPLITS:\n","    print 'Making train/test splits'\n","    with open(os.path.join(DATA_PATH, 'scenes.json')) as f:\n","        scene_vec = json.loads(f.read())\n","    scene_id_set = set()\n","    for scene in tqdm(scene_vec):\n","        scene_id = scene['assignmentId']\n","        scene_id_set.add(scene_id)\n","    \n","    print(\"Get Scene ID completed\")\n","    scene_id_list = list(scene_id_set)\n","    np.random.seed(0)\n","    np.random.shuffle(scene_id_list)\n","    \n","    print(\"Shuffle completed\")\n","    \n","    train_fraction = 0.8\n","    val_fraction = 0.1\n","    test_fraction = 0.1\n","    assert train_fraction + val_fraction + test_fraction == 1\n","    train_val_cutoff = int(train_fraction * len(scene_id_list))\n","    val_test_cutoff = int((train_fraction + val_fraction) * len(scene_id_list))\n","    split_dict = dict()\n","    for (index, scene_id) in tqdm(enumerate(scene_id_list)):\n","        if index < train_val_cutoff:\n","            split_dict[scene_id] = 'train'\n","        elif train_val_cutoff <= index < val_test_cutoff:\n","            split_dict[scene_id] = 'val'\n","        else:\n","            split_dict[scene_id] = 'test'\n","    \n","    print 'Number of scenes for train set: ', sum([split == 'train' for split in split_dict.values()])\n","    print 'Number of scenes for test set: ', sum([split == 'test' for split in split_dict.values()])\n","    print 'Number of scenes for validation set: ', sum([split == 'val' for split in split_dict.values()])\n","    print 'Number of scenes total: ', len(split_dict.values())\n","    \n","    with open(os.path.join(DATA_PATH, 'split_dict_%02d.json' % 0), 'wb') as f:\n","        json.dump(split_dict, f)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Making train/test splits\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 9704/9704 [00:00<00:00, 314778.78it/s]\n","1213it [00:00, 115555.80it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Get Scene ID completed\n","Shuffle completed\n","Number of scenes for train set:  970\n","Number of scenes for test set:  122\n","Number of scenes for validation set:  121\n","Number of scenes total:  1213\n"],"name":"stdout"}]},{"metadata":{"id":"9nUnk5ZSRwoG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"02359552-2b49-4504-aaa6-5decaf430f27"},"cell_type":"code","source":["!"],"execution_count":0,"outputs":[{"output_type":"error","ename":"IOError","evalue":"[Errno 2] No such file or directory: '\\\\data/egocentric_image_features.npy'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-87cb2a6f7bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_features_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'egocentric_image_features.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/home/drsung2410/mistaken/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '\\\\data/egocentric_image_features.npy'"]}]},{"metadata":{"id":"Grx47razRwoK","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["os.path.join(DATA_PATH, 'egocentric_image_features.npy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L2QYFHYtRwoN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"2ff52e14-7bf8-4674-fb4f-18f893d41944"},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive\t  Python-2.7.14      Untitled1.ipynb\n","mistaken  Python-2.7.14.tgz  Untitled.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"f_VT3sq4RwoU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["with open(os.path.join(DATA_PATH, 'scenes.json')) as f:\n","        frame_vec = json.loads(f.read())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lUsfZVoVRwoV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["feature_hash = abs(hash('testmodel'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Yg3Br6c-Rwoa","colab_type":"text"},"cell_type":"markdown","source":["#### Concatenate Features"]},{"metadata":{"id":"_31ugOsJRwoc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"15317513-3880-4d86-a97c-dadc65ea1765"},"cell_type":"code","source":["CONCATENATE_FEATURES = True\n","USE_CAFFENET_FEATURE = True\n","LOOKBEHIND = 3\n","LOOKAHEAD = 3\n","if CONCATENATE_FEATURES and not os.path.exists('X_%d.npy' % feature_hash):\n","    print 'Concatenating features'\n","\n","    ANY_IMAGE_FEATURE = USE_CAFFENET_FEATURE\n","    POOL = False\n","    if USE_CAFFENET_FEATURE:\n","        frame_dict_filename = os.path.join(DATA_PATH, 'frame_dict_cnn.json')\n","        print(\"Load egocentric_image_features.npy file\")\n","        image_features_filename = os.path.join(DATA_PATH, 'egocentric_image_features.npy')\n","        \n","        blocksize = 1024  # tune this for performance/granularity\n","        mmap = None\n","        try:\n","            mmap = np.load(image_features_filename, mmap_mode='r')\n","            image_feature_matrix = np.empty_like(mmap)\n","            n_blocks = int(np.ceil(mmap.shape[0] / blocksize))\n","            for b in tqdm(range(n_blocks)):\n","                image_feature_matrix[b*blocksize : (b+1) * blocksize] = mmap[b*blocksize : (b+1) * blocksize]\n","        finally:\n","            del mmap  # make sure file is closed again\n","        #image_feature_matrix = np.load(image_features_filename)\n","        \n","        print(\"Load frame_dict_cnn.json file\")\n","        with open(frame_dict_filename) as f:\n","            frame_dict = json.load(f)\n","\n","        pool5_size = (256, 12, 21)\n","\n","    else:\n","        print 'WARNING: no image features used.\\n'\n","        frame_dict_filename = os.path.join(DATA_PATH, 'frame_dict_cnn.json')\n","        with open(frame_dict_filename) as f:\n","            frame_dict = json.load(f)\n","\n","\n","    print(\"Load other feature\")\n","    question_dict_filename = os.path.join(DATA_PATH, 'question_dict.json')\n","    xytf_filename = os.path.join(DATA_PATH, 'xytf_dict.json') \n","    name_expression_filename = os.path.join(DATA_PATH, 'name_expression_dict.json')\n","    present_filename = os.path.join(DATA_PATH, 'present_dict.json')\n","\n","    with open(question_dict_filename) as f:\n","        question_dict = json.load(f)\n","\n","    with open(xytf_filename) as f:\n","        xytf_dict = json.load(f)\n","    \n","    with open(name_expression_filename) as f:\n","        name_expression_dict = json.load(f)\n","\n","    with open(present_filename) as f:\n","        present_dict = json.load(f)\n","    \n","\n","    X = []\n","    y = []\n","    t = []\n","\n","    scene_id_vec = []\n","    image_filename_vec = []\n","    concat_indices = dict()\n","\n","    for scene_frame_character in tqdm(frame_dict.keys()):\n","        if 'flipped' in scene_frame_character:\n","            continue\n","        (scene_id, frame_index, character_name) = scene_frame_character.split('_')\n","        frame_index = int(frame_index)\n","        frame_key = '%s_%d' % (scene_id, frame_index)\n","        question_vec = question_dict[frame_key]['questions']\n","        answer_dict_vec = question_dict[frame_key]['answers']\n","        \n","        if character_name not in ['all', 'none', 'centered']:\n","            assert 'Doll' in character_name, 'Character name: %s' % character_name\n","            \n","            if ANY_IMAGE_FEATURE:\n","                image_feature_vec = []\n","                for other_frame_index in range(frame_index - LOOKBEHIND, frame_index + LOOKAHEAD + 1):\n","                    key = '%s_%d_%s' % (scene_id, other_frame_index, character_name)\n","                    \n","                    if key in frame_dict.keys():\n","                        image_feature_index = frame_dict[key]\n","                        pool5 = image_feature_matrix[image_feature_index].flatten()\n","                    else: # Character is not present\n","                        pool5 = np.zeros(pool5_size).flatten()\n","                    \n","                    if POOL:\n","                        pool5 = pool5.reshape(pool5_size)\n","                        if pool5.shape[1] % 2 == 1:\n","                            pool5 = pool5[:, :-1]\n","                        if pool5.shape[2] % 2 == 1:\n","                            pool5 = pool5[:, :, :-1]\n","                        (c, h, w) = pool5.shape\n","                        pool5 = pool5.reshape((c, h / 2, 2, w / 2, 2)).max(axis=4).max(axis=2).flatten()\n","                    image_feature_vec.append(pool5)\n","\n","                image_feature = np.hstack(image_feature_vec) \n","                \n","            answer_vec = []\n","            for answer_dict in answer_dict_vec:\n","                answer = int(answer_dict[character_name] == answer_dict['omniscient'] )\n","                answer_vec.append(answer)\n","            if answer_vec[0] != answer_vec[1]:\n","                continue\n","\n","            # Only used for visualization\n","            question = question_vec[0]\n","            image_filename_vec.append('%s_%02d.png' % (scene_id, frame_index))\n","             \n","            answer_dict = answer_dict_vec[0]\n","            assert answer_dict[character_name] in ['yes', 'no']\n","            answer = int(answer_dict[character_name] == answer_dict['omniscient'])\n","            assert answer == answer_vec[0]\n","            \n","            xytf = xytf_dict[scene_frame_character]\n","\n","            feature = []\n","            if ANY_IMAGE_FEATURE:\n","                feature.append(image_feature)\n","            if False:\n","                feature.append([float(answer)])\n","            if False:\n","                feature.append([xytf['x'] / 700.0, xytf['y'] / 400.0])\n","            if False:\n","                feature.append([xytf['t'] / 8.0])\n","            if False:\n","                feature.append(name_expression_dict[scene_frame_character]['name_one_hot'])\n","            if False:\n","                feature.append(name_expression_dict[scene_frame_character]['expression_one_hot'])\n","            if False:\n","                feature.append(present_dict[scene_frame_character])\n","\n","\n","            index = len(X)\n","            assert len(X) == len(y)\n","            assert scene_frame_character not in concat_indices\n","            concat_indices[scene_frame_character] = index\n","\n","            X.append(np.hstack(feature))\n","            y.append(answer)\n","            t.append(xytf['t'])\n","            scene_id_vec.append(scene_id)\n","            \n","            \n","    X = np.array(X)\n","    y = np.array(y)\n","    t = np.array(t)\n","    assert X.shape[0] == len(y) == len(t)\n","\n","\n","\n","    print 'X.shape:', X.shape\n","    print 'y.shape:', y.shape\n","    print 'Number of rows:', len(X)\n","    print 'Number of unique rows:', len(set([hash(row.tostring()) for row in X]))\n","    \n","    np.save('X_%d.npy' % feature_hash, X)\n","    np.save('y_%d.npy' % feature_hash, y)\n","    np.save('t_%d.npy' % feature_hash, t)\n","    \n","    with open('concat_indices_%d.json' % feature_hash, 'wb') as f:\n","        json.dump(concat_indices, f)\n"," \n","    with open('scene_id_vec_%d.json' % feature_hash, 'wb') as f:\n","        json.dump(scene_id_vec, f)\n","\n","    with open('image_filename_vec_%d.json' % feature_hash, 'wb') as f:\n","        json.dump(image_filename_vec, f)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Concatenating features\n","Load egocentric_image_features.npy file\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 41/41 [06:24<00:00,  9.38s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Load frame_dict_cnn.json file\n","Load other feature\n"],"name":"stdout"},{"output_type":"stream","text":[" 21%|██        | 8892/42922 [01:27<05:36, 101.17it/s]"],"name":"stderr"}]},{"metadata":{"id":"w0EDVzGqRwog","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"7bd380b7-0d9f-4fed-fb25-9685f9252158"},"cell_type":"code","source":["!ls\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive\t  Python-2.7.14      Untitled1.ipynb\n","mistaken  Python-2.7.14.tgz  Untitled.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"kLGZapL8Rwok","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZLZU_s6QRwoq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UafTxsdogUJN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["a = np.load('/tmp/123.npy', mmap_mode='r')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rgq1cUVeghPn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"71853a2c-094c-41ae-ed63-839ca3d21ead","executionInfo":{"status":"ok","timestamp":1520477283386,"user_tz":-420,"elapsed":821,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["a\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["memmap([[1, 2, 3],\n","        [4, 5, 6]])"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"vK6hEh6MgiDH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"5af5dce7-da4b-46fe-d72f-cf6def1be9b0","executionInfo":{"status":"ok","timestamp":1520477290832,"user_tz":-420,"elapsed":1527,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["a[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["memmap([1, 2, 3])"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"NqXtKYw5gjsX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"74b42e11-db8e-45b1-a033-45188856d218","executionInfo":{"status":"ok","timestamp":1520477296415,"user_tz":-420,"elapsed":1292,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["type(a[0])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.core.memmap.memmap"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"jmtje2tvglHX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["b = np.array([1,2,3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ebZqWT7zgzDW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"87a6d371-a995-413d-8f23-2caf4943510e","executionInfo":{"status":"ok","timestamp":1520477368432,"user_tz":-420,"elapsed":2016,"user":{"displayName":"Thạch Hoàng Ngọc","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101752767182448615555"}}},"cell_type":"code","source":["a[0] + b"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2, 4, 6])"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"k4FsFyFeg2hH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}